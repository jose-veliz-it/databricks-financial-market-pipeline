{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faa486c1-cc6d-40fb-8567-36c4aa2c7a76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# NOTEBOOK: 02_Ingest_to_Bronze\n",
    "# PURPOSE: Fetch stock data from Alpha Vantage API and save to Bronze layer\n",
    "# AUTHOR: Jose Veliz\n",
    "# DATE: 2025-10-17\n",
    "# ===================================================================\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Initialize Spark (already running in Databricks)\n",
    "spark = spark\n",
    "\n",
    "print(\"✅ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0153336-7a6e-4377-bd2f-060ef123ee00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# CONFIGURATION\n",
    "# ===================================================================\n",
    "\n",
    "# Your Alpha Vantage API key\n",
    "API_KEY = \"5DUCAA0WEXYCTWHG\"  # ← REPLACE THIS WITH YOUR ACTUAL KEY\n",
    "\n",
    "# API endpoint\n",
    "BASE_URL = \"https://www.alphavantage.co/query\"\n",
    "\n",
    "# Stocks to track (start with 5)\n",
    "SYMBOLS = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\"]\n",
    "\n",
    "# Bronze layer path (where we'll save raw data)\n",
    "BRONZE_PATH = \"/FileStore/bronze_stock_prices\"\n",
    "\n",
    "print(f\"✅ Configuration set\")\n",
    "print(f\"   Tracking {len(SYMBOLS)} stocks: {', '.join(SYMBOLS)}\")\n",
    "print(f\"   Bronze path: {BRONZE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11b62418-7aef-4c24-9df0-794e5a4cd602",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# FUNCTION: Fetch stock data from API\n",
    "# ===================================================================\n",
    "\n",
    "def fetch_stock_data(symbol):\n",
    "    \"\"\"\n",
    "    Fetch daily stock prices for a given symbol from Alpha Vantage API\n",
    "    \n",
    "    Args:\n",
    "        symbol (str): Stock symbol (e.g., 'AAPL')\n",
    "    \n",
    "    Returns:\n",
    "        list: List of records with stock data\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"function\": \"TIME_SERIES_DAILY\",\n",
    "        \"symbol\": symbol,\n",
    "        \"apikey\": API_KEY,\n",
    "        \"outputsize\": \"compact\"  # Last 100 days\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(BASE_URL, params=params)\n",
    "        data = response.json()\n",
    "        \n",
    "        # Check for errors\n",
    "        if \"Time Series (Daily)\" not in data:\n",
    "            error_msg = data.get(\"Note\", data.get(\"Error Message\", \"Unknown error\"))\n",
    "            print(f\"❌ Error fetching {symbol}: {error_msg}\")\n",
    "            return None\n",
    "        \n",
    "        # Extract time series data\n",
    "        time_series = data[\"Time Series (Daily)\"]\n",
    "        \n",
    "        # Convert to list of records\n",
    "        records = []\n",
    "        for date_str, values in time_series.items():\n",
    "            record = {\n",
    "                \"symbol\": symbol,\n",
    "                \"date\": date_str,\n",
    "                \"open\": values[\"1. open\"],\n",
    "                \"high\": values[\"2. high\"],\n",
    "                \"low\": values[\"3. low\"],\n",
    "                \"close\": values[\"4. close\"],\n",
    "                \"volume\": values[\"5. volume\"],\n",
    "                \"ingestion_timestamp\": datetime.now().isoformat(),\n",
    "                \"source\": \"alphavantage\"\n",
    "            }\n",
    "            records.append(record)\n",
    "        \n",
    "        print(f\"✅ Fetched {len(records)} records for {symbol}\")\n",
    "        return records\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Exception fetching {symbol}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\"✅ Function defined: fetch_stock_data()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "455dcf8d-54e3-4116-9017-f260710eb2d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# FETCH DATA FOR ALL SYMBOLS\n",
    "# ===================================================================\n",
    "\n",
    "import time\n",
    "\n",
    "all_records = []\n",
    "\n",
    "print(f\"\\n\uD83D\uDD04 Starting data fetch for {len(SYMBOLS)} symbols...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, symbol in enumerate(SYMBOLS, 1):\n",
    "    print(f\"\\n[{i}/{len(SYMBOLS)}] Fetching {symbol}...\")\n",
    "    \n",
    "    records = fetch_stock_data(symbol)\n",
    "    \n",
    "    if records:\n",
    "        all_records.extend(records)\n",
    "        print(f\"    ✅ Success! Total records so far: {len(all_records)}\")\n",
    "    \n",
    "    # Be nice to the API (5 calls/minute limit)\n",
    "    # Wait 15 seconds between calls\n",
    "    if i < len(SYMBOLS):  # Don't wait after last symbol\n",
    "        print(f\"    ⏳ Waiting 15 seconds (API rate limit)...\")\n",
    "        time.sleep(15)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n✅ DATA FETCH COMPLETE!\")\n",
    "print(f\"   Total records fetched: {len(all_records)}\")\n",
    "print(f\"   From {len(SYMBOLS)} stocks\")\n",
    "# ```\n",
    "\n",
    "#**Click Run**\n",
    "\n",
    "# **You should see:**\n",
    "# ```\n",
    "# [1/5] Fetching AAPL...\n",
    "#     ✅ Success! Total records so far: 100\n",
    "#     ⏳ Waiting 15 seconds (API rate limit)...\n",
    "\n",
    "# [2/5] Fetching MSFT...\n",
    "#     ✅ Success! Total records so far: 200\n",
    "#     ⏳ Waiting 15 seconds (API rate limit)...\n",
    "\n",
    "# ... (continues for all 5 stocks)\n",
    "\n",
    "# ✅ DATA FETCH COMPLETE!\n",
    "#    Total records fetched: 500\n",
    "#    From 5 stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05f1401f-f7fd-4662-b465-aff7d875c2cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# CONVERT TO SPARK DATAFRAME\n",
    "# ===================================================================\n",
    "\n",
    "# Create Spark DataFrame from records\n",
    "df = spark.createDataFrame(all_records)\n",
    "\n",
    "print(\"✅ Spark DataFrame created\")\n",
    "print(f\"\\n\uD83D\uDCCA DATAFRAME SUMMARY:\")\n",
    "print(f\"   Rows: {df.count()}\")\n",
    "print(f\"   Columns: {len(df.columns)}\")\n",
    "\n",
    "print(f\"\\n\uD83D\uDCCB SCHEMA:\")\n",
    "df.printSchema()\n",
    "\n",
    "print(f\"\\n\uD83D\uDC40 SAMPLE DATA (first 10 rows):\")\n",
    "df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e411de0c-c53f-4217-9085-42b4e9ff3bf8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# SAVE TO BRONZE LAYER (AS MANAGED TABLE)\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\uD83D\uDCBE Writing data to Bronze layer (as managed table)...\")\n",
    "\n",
    "# Create a temporary view first\n",
    "df.createOrReplaceTempView(\"bronze_stock_prices_temp\")\n",
    "\n",
    "# Write to managed Delta table (stored in default database)\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE bronze_stock_prices\n",
    "    USING DELTA\n",
    "    PARTITIONED BY (date)\n",
    "    AS SELECT * FROM bronze_stock_prices_temp\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n✅ DATA WRITTEN TO BRONZE LAYER!\")\n",
    "print(f\"   Total rows: {df.count()}\")\n",
    "print(f\"   Format: Delta Table (managed)\")\n",
    "print(f\"   Table name: bronze_stock_prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "478881d3-692e-48ab-8bd7-3a92bb40dad6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# VERIFY BRONZE LAYER (READ FROM TABLE)\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\uD83D\uDD0D Verifying Bronze layer...\")\n",
    "\n",
    "# Read data back from Bronze table\n",
    "bronze_df = spark.table(\"bronze_stock_prices\")\n",
    "\n",
    "print(f\"\\n✅ BRONZE LAYER VERIFICATION:\")\n",
    "print(f\"   Row count: {bronze_df.count()}\")\n",
    "print(f\"   Unique symbols: {bronze_df.select('symbol').distinct().count()}\")\n",
    "print(f\"   Date range: {bronze_df.agg(min('date'), max('date')).collect()[0]}\")\n",
    "\n",
    "print(f\"\\n\uD83D\uDC40 SAMPLE OF BRONZE DATA:\")\n",
    "bronze_df.orderBy(desc(\"date\")).show(10)\n",
    "\n",
    "print(\"\\n\uD83C\uDF89 BRONZE LAYER COMPLETE!\")\n",
    "# ```\n",
    "\n",
    "# ---\n",
    "\n",
    "# # \uD83C\uDFAF WHAT TO DO NOW:\n",
    "\n",
    "# ## **Step 1: Update Cell 6 (2 minutes)**\n",
    "\n",
    "# 1. **Scroll to Cell 6** in your notebook\n",
    "# 2. **Delete everything** in that cell\n",
    "# 3. **Copy-paste the new Cell 6 code** (from above - the one that creates a TABLE)\n",
    "# 4. **Click Run**\n",
    "\n",
    "# **You should see:**\n",
    "# ```\n",
    "# \uD83D\uDCBE Writing data to Bronze layer (as managed table)...\n",
    "\n",
    "# ✅ DATA WRITTEN TO BRONZE LAYER!\n",
    "#    Total rows: 500\n",
    "#    Format: Delta Table (managed)\n",
    "#    Table name: bronze_stock_prices\n",
    "# ```\n",
    "\n",
    "# ---\n",
    "\n",
    "# ## **Step 2: Update Cell 7 (2 minutes)**\n",
    "\n",
    "# 1. **Scroll to Cell 7**\n",
    "# 2. **Delete everything** in that cell\n",
    "# 3. **Copy-paste the new Cell 7 code** (from above - the one that reads from TABLE)\n",
    "# 4. **Click Run**\n",
    "\n",
    "# **You should see:**\n",
    "# ```\n",
    "# \uD83D\uDD0D Verifying Bronze layer...\n",
    "\n",
    "# ✅ BRONZE LAYER VERIFICATION:\n",
    "#    Row count: 500\n",
    "#    Unique symbols: 5\n",
    "#    Date range: Row(min(date)='2025-07-10', max(date)='2025-10-17')\n",
    "\n",
    "# \uD83D\uDC40 SAMPLE OF BRONZE DATA:\n",
    "# [Table showing your stock data]\n",
    "\n",
    "# \uD83C\uDF89 BRONZE LAYER COMPLETE!"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_Ingest_to_Bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}