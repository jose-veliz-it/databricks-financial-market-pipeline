{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6295c54c-bca7-4c09-b8b8-118a38321aaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# NOTEBOOK: 04_Silver_to_Gold\n",
    "# PURPOSE: Create business-ready analytics from Silver layer\n",
    "# AUTHOR: Jose Veliz - Space Cowboy \n",
    "# DATE: 2025-10-19\n",
    "# ===================================================================\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Spark is already initialized\n",
    "spark = spark\n",
    "\n",
    "print(\" Libraries imported\")\n",
    "print(\" Space Cowboy's Gold Layer Analytics\")\n",
    "print(\" Final layer - Business-ready insights!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc7bca20-86e1-40d8-9895-6e976ef2b5d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# READ FROM SILVER LAYER\n",
    "# ===================================================================\n",
    "\n",
    "print(\" Reading data from Silver layer...\")\n",
    "\n",
    "# Read from Silver table\n",
    "silver_df = spark.table(\"silver_stock_prices\")\n",
    "\n",
    "print(f\"\\n SILVER DATA LOADED:\")\n",
    "print(f\"   Total rows: {silver_df.count():,}\")\n",
    "print(f\"   Symbols: {silver_df.select('symbol').distinct().count()}\")\n",
    "print(f\"   Date range: {silver_df.agg(min('date'), max('date')).collect()[0]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3c51a2b-8438-4c33-af97-b9ca387b6f2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# GOLD TABLE 1: DAILY STOCK SUMMARY\n",
    "# ===================================================================\n",
    "\n",
    "print(\" Creating Gold Table 1: Daily Stock Summary\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Aggregate by date to get market-wide daily summary\n",
    "gold_daily_summary = silver_df.groupBy(\"date\").agg(\n",
    "    # Trading activity\n",
    "    count(\"symbol\").alias(\"stocks_traded\"),\n",
    "    sum(\"volume\").alias(\"total_volume\"),\n",
    "    \n",
    "    # Price metrics (across all stocks)\n",
    "    round(avg(\"close\"), 2).alias(\"avg_closing_price\"),\n",
    "    round(avg(\"daily_change_pct\"), 2).alias(\"avg_daily_change_pct\"),\n",
    "    round(avg(\"price_range_pct\"), 2).alias(\"avg_volatility_pct\"),\n",
    "    \n",
    "    # Market breadth (how many stocks up vs down)\n",
    "    sum(when(col(\"daily_change_pct\") > 0, 1).otherwise(0)).alias(\"stocks_up\"),\n",
    "    sum(when(col(\"daily_change_pct\") < 0, 1).otherwise(0)).alias(\"stocks_down\"),\n",
    "    sum(when(col(\"daily_change_pct\") == 0, 1).otherwise(0)).alias(\"stocks_flat\"),\n",
    "    \n",
    "    # Extremes\n",
    "    round(max(\"daily_change_pct\"), 2).alias(\"biggest_gainer_pct\"),\n",
    "    round(min(\"daily_change_pct\"), 2).alias(\"biggest_loser_pct\")\n",
    ").orderBy(\"date\")\n",
    "\n",
    "# Add derived metrics\n",
    "gold_daily_summary = gold_daily_summary.withColumn(\n",
    "    \"market_sentiment\",\n",
    "    when(col(\"stocks_up\") > col(\"stocks_down\"), \"BULLISH\")\n",
    "    .when(col(\"stocks_up\") < col(\"stocks_down\"), \"BEARISH\")\n",
    "    .otherwise(\"NEUTRAL\")\n",
    ").withColumn(\n",
    "    \"gold_processing_timestamp\",\n",
    "    current_timestamp()\n",
    ")\n",
    "\n",
    "print(f\"\\n Daily Summary Table Created:\")\n",
    "print(f\"   Rows: {gold_daily_summary.count()}\")\n",
    "print(f\"   Columns: {len(gold_daily_summary.columns)}\")\n",
    "\n",
    "print(\"\\n SAMPLE (Most Recent Days):\")\n",
    "gold_daily_summary.orderBy(desc(\"date\")).show(10, truncate=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0f5e7d3-d3e6-4835-9902-12d39edd737e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# GOLD TABLE 2: STOCK PERFORMANCE METRICS\n",
    "# ===================================================================\n",
    "\n",
    "print(\" Creating Gold Table 2: Stock Performance Metrics\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Aggregate by symbol for overall performance metrics\n",
    "gold_stock_performance = silver_df.groupBy(\"symbol\").agg(\n",
    "    # Basic stats\n",
    "    count(\"*\").alias(\"trading_days\"),\n",
    "    round(avg(\"close\"), 2).alias(\"avg_closing_price\"),\n",
    "    round(min(\"close\"), 2).alias(\"min_closing_price\"),\n",
    "    round(max(\"close\"), 2).alias(\"max_closing_price\"),\n",
    "    \n",
    "    # Performance\n",
    "    round(avg(\"daily_change_pct\"), 2).alias(\"avg_daily_change_pct\"),\n",
    "    round(stddev(\"daily_change_pct\"), 2).alias(\"volatility_stddev\"),\n",
    "    round(sum(\"daily_change_pct\"), 2).alias(\"cumulative_change_pct\"),\n",
    "    \n",
    "    # Volume\n",
    "    round(avg(\"volume\"), 0).alias(\"avg_daily_volume\"),\n",
    "    sum(\"volume\").alias(\"total_volume\"),\n",
    "    \n",
    "    # Winning days vs losing days\n",
    "    sum(when(col(\"daily_change_pct\") > 0, 1).otherwise(0)).alias(\"winning_days\"),\n",
    "    sum(when(col(\"daily_change_pct\") < 0, 1).otherwise(0)).alias(\"losing_days\"),\n",
    "    \n",
    "    # Best and worst days\n",
    "    round(max(\"daily_change_pct\"), 2).alias(\"best_day_pct\"),\n",
    "    round(min(\"daily_change_pct\"), 2).alias(\"worst_day_pct\"),\n",
    "    \n",
    "    # Price range\n",
    "    round(avg(\"price_range_pct\"), 2).alias(\"avg_intraday_range_pct\")\n",
    ")\n",
    "\n",
    "# Add derived metrics\n",
    "gold_stock_performance = gold_stock_performance.withColumn(\n",
    "    \"win_rate_pct\",\n",
    "    round((col(\"winning_days\") / col(\"trading_days\")) * 100, 1)\n",
    ").withColumn(\n",
    "    \"risk_reward_ratio\",\n",
    "    round(abs(col(\"avg_daily_change_pct\")) / col(\"volatility_stddev\"), 2)\n",
    ").withColumn(\n",
    "    \"performance_rating\",\n",
    "    when(col(\"cumulative_change_pct\") > 15, \"STRONG\")\n",
    "    .when(col(\"cumulative_change_pct\") > 5, \"GOOD\")\n",
    "    .when(col(\"cumulative_change_pct\") > -5, \"NEUTRAL\")\n",
    "    .when(col(\"cumulative_change_pct\") > -15, \"WEAK\")\n",
    "    .otherwise(\"POOR\")\n",
    ").withColumn(\n",
    "    \"gold_processing_timestamp\",\n",
    "    current_timestamp()\n",
    ").orderBy(desc(\"cumulative_change_pct\"))\n",
    "\n",
    "print(f\"\\n Stock Performance Table Created:\")\n",
    "print(f\"   Rows: {gold_stock_performance.count()}\")\n",
    "print(f\"   Columns: {len(gold_stock_performance.columns)}\")\n",
    "\n",
    "print(\"\\n STOCK PERFORMANCE RANKINGS:\")\n",
    "gold_stock_performance.select(\n",
    "    \"symbol\",\n",
    "    \"cumulative_change_pct\",\n",
    "    \"avg_daily_change_pct\",\n",
    "    \"volatility_stddev\",\n",
    "    \"win_rate_pct\",\n",
    "    \"performance_rating\"\n",
    ").show(truncate=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d8240dd-a2b7-4708-9f1e-192483888dad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# GOLD TABLE 3: TOP PERFORMERS (DAILY GAINERS/LOSERS)\n",
    "# ===================================================================\n",
    "\n",
    "print(\" Creating Gold Table 3: Top Performers Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get top 3 gainers and losers for each date\n",
    "window_spec = Window.partitionBy(\"date\").orderBy(desc(\"daily_change_pct\"))\n",
    "\n",
    "gold_top_performers = silver_df.select(\n",
    "    \"date\",\n",
    "    \"symbol\",\n",
    "    \"open\",\n",
    "    \"close\",\n",
    "    \"daily_change\",\n",
    "    \"daily_change_pct\",\n",
    "    \"volume\",\n",
    "    row_number().over(window_spec).alias(\"rank\")\n",
    ").filter(col(\"rank\") <= 3)  # Top 3 gainers each day\n",
    "\n",
    "# Add category\n",
    "gold_top_performers = gold_top_performers.withColumn(\n",
    "    \"category\", lit(\"TOP_GAINER\")\n",
    ").withColumn(\n",
    "    \"gold_processing_timestamp\", current_timestamp()\n",
    ")\n",
    "\n",
    "# Get top 3 losers\n",
    "window_spec_losers = Window.partitionBy(\"date\").orderBy(\"daily_change_pct\")\n",
    "\n",
    "gold_top_losers = silver_df.select(\n",
    "    \"date\",\n",
    "    \"symbol\",\n",
    "    \"open\",\n",
    "    \"close\",\n",
    "    \"daily_change\",\n",
    "    \"daily_change_pct\",\n",
    "    \"volume\",\n",
    "    row_number().over(window_spec_losers).alias(\"rank\")\n",
    ").filter(col(\"rank\") <= 3)  # Top 3 losers each day\n",
    "\n",
    "gold_top_losers = gold_top_losers.withColumn(\n",
    "    \"category\", lit(\"TOP_LOSER\")\n",
    ").withColumn(\n",
    "    \"gold_processing_timestamp\", current_timestamp()\n",
    ")\n",
    "\n",
    "# Combine gainers and losers\n",
    "gold_top_performers_combined = gold_top_performers.union(gold_top_losers)\n",
    "\n",
    "print(f\"\\n Top Performers Table Created:\")\n",
    "print(f\"   Rows: {gold_top_performers_combined.count()}\")\n",
    "print(f\"   (Top 3 gainers + top 3 losers per day)\")\n",
    "\n",
    "print(\"\\n MOST RECENT DAY - TOP GAINERS:\")\n",
    "gold_top_performers.filter(col(\"rank\") <= 3).orderBy(desc(\"date\"), \"rank\").limit(3).show(truncate=False)\n",
    "\n",
    "print(\"\\n MOST RECENT DAY - TOP LOSERS:\")\n",
    "gold_top_losers.filter(col(\"rank\") <= 3).orderBy(desc(\"date\"), \"rank\").limit(3).show(truncate=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb096cb4-2c87-4e82-86cf-a6c78c302ab8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# SAVE ALL GOLD TABLES\n",
    "# ===================================================================\n",
    "\n",
    "print(\" Saving Gold layer tables...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Table 1: Daily Summary\n",
    "print(\"\\n Saving gold_daily_summary...\")\n",
    "gold_daily_summary.createOrReplaceTempView(\"gold_daily_summary_temp\")\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE gold_daily_summary\n",
    "    USING DELTA\n",
    "    AS SELECT * FROM gold_daily_summary_temp\n",
    "\"\"\")\n",
    "print(f\"   Saved: gold_daily_summary ({gold_daily_summary.count()} rows)\")\n",
    "\n",
    "# Table 2: Stock Performance\n",
    "print(\"\\n Saving gold_stock_performance...\")\n",
    "gold_stock_performance.createOrReplaceTempView(\"gold_stock_performance_temp\")\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE gold_stock_performance\n",
    "    USING DELTA\n",
    "    AS SELECT * FROM gold_stock_performance_temp\n",
    "\"\"\")\n",
    "print(f\"   Saved: gold_stock_performance ({gold_stock_performance.count()} rows)\")\n",
    "\n",
    "# Table 3: Top Performers\n",
    "print(\"\\n Saving gold_top_performers...\")\n",
    "gold_top_performers_combined.createOrReplaceTempView(\"gold_top_performers_temp\")\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE gold_top_performers\n",
    "    USING DELTA\n",
    "    PARTITIONED BY (date)\n",
    "    AS SELECT * FROM gold_top_performers_temp\n",
    "\"\"\")\n",
    "print(f\"   Saved: gold_top_performers ({gold_top_performers_combined.count()} rows)\")\n",
    "\n",
    "print(\"\\n ALL GOLD TABLES SAVED!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Saving Gold layer tables...\n",
    "# ============================================================\n",
    "\n",
    "# 1️⃣ Saving gold_daily_summary...\n",
    "#    ✅ Saved: gold_daily_summary (100 rows)\n",
    "# 2️⃣ Saving gold_stock_performance...\n",
    "#    ✅ Saved: gold_stock_performance (5 rows)\n",
    "# 3️⃣ Saving gold_top_performers...\n",
    "#    ✅ Saved: gold_top_performers (600 rows)\n",
    "# ✅ ALL GOLD TABLES SAVED!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "513742fe-e386-4306-9627-fe8d17f97491",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# FINAL VERIFICATION & PIPELINE SUMMARY\n",
    "# ===================================================================\n",
    "\n",
    "print(\" Final verification of complete pipeline...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n BRONZE LAYER:\")\n",
    "bronze_count = spark.table(\"bronze_stock_prices\").count()\n",
    "print(f\"   Table: bronze_stock_prices\")\n",
    "print(f\"   Rows: {bronze_count:,}\")\n",
    "print(f\"   Purpose: Raw data from API\")\n",
    "\n",
    "print(\"\\n SILVER LAYER:\")\n",
    "silver_count = spark.table(\"silver_stock_prices\").count()\n",
    "print(f\"   Table: silver_stock_prices\")\n",
    "print(f\"   Rows: {silver_count:,}\")\n",
    "print(f\"   Purpose: Cleaned & transformed data\")\n",
    "\n",
    "print(\"\\n GOLD LAYER:\")\n",
    "gold1_count = spark.table(\"gold_daily_summary\").count()\n",
    "gold2_count = spark.table(\"gold_stock_performance\").count()\n",
    "gold3_count = spark.table(\"gold_top_performers\").count()\n",
    "print(f\"   Table 1: gold_daily_summary ({gold1_count} rows)\")\n",
    "print(f\"   Table 2: gold_stock_performance ({gold2_count} rows)\")\n",
    "print(f\"   Table 3: gold_top_performers ({gold3_count} rows)\")\n",
    "print(f\"   Purpose: Business-ready analytics\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" COMPLETE DATA PIPELINE BUILT! \")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n\uD83C\uDFC6 MEDALLION ARCHITECTURE:\")\n",
    "print(\"   ✅ Bronze → Raw ingestion\")\n",
    "print(\"   ✅ Silver → Data quality & transformation\")\n",
    "print(\"   ✅ Gold → Business analytics\")\n",
    "print(\"\\n\uD83D\uDC8E TECHNOLOGIES DEMONSTRATED:\")\n",
    "print(\"   ✅ Databricks\")\n",
    "print(\"   ✅ Delta Lake\")\n",
    "print(\"   ✅ PySpark\")\n",
    "print(\"   ✅ REST API integration\")\n",
    "print(\"   ✅ Medallion architecture\")\n",
    "print(\"   ✅ Data quality checks\")\n",
    "print(\"   ✅ Performance optimization (partitioning)\")\n",
    "print(\"\\n Space Cowboy has landed on the moon! \")\n",
    "print(\"=\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_Silver_to_Gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}